# Chapter 8: Main Memory

## Background

Main memory is central to the operation of a modern computer system. Main memory is a large array of words or bytes, ranging in size from hundreds of thousands to billions. Each word or byte has its own address. The CPU fetches instructions from memory according to the value of the program counter.

For a program to be executed, it must be mapped to absolute addresses and loaded into memory. As the process executes, it accesses program instructions and data from memory by generating these absolute addresses.

### Basic Hardware

Main memory and the registers built into the processor itself are the only storage that the CPU can access directly. Any instructions and data must be in one of these direct-access storage devices. If the data are not in memory, they must be moved there before the CPU can operate on them.

Registers that are built into the CPU are generally accessible within one cycle of the CPU clock. Accessing main memory, on the other hand, may take many cycles of the CPU clock. To remedy this, a fast memory called a **cache** is used to store frequently used data.

### Memory Protection

We need to make sure that a process can access only those memory addresses that have been allocated to it. This protection can be provided by using two registers, usually a **base register** and a **limit register**. The base register holds the smallest legal physical memory address; the limit register specifies the size of the range.

## Swapping

A process must be in memory to be executed. A process, however, can be swapped temporarily out of memory to a **backing store** (a large, fast disk) and then brought back into memory for continued execution.

Swapping makes it possible for the total physical address space of all processes to exceed the real physical memory of the system, thus increasing the degree of multiprogramming in a system.

## Contiguous Memory Allocation

One of the simplest methods for memory allocation is to divide memory into several fixed-sized partitions. Each partition may contain exactly one process. In this **multiple-partition method**, when a partition is free, a process is selected from the input queue and is loaded into the free partition.

A variation is the **variable-partition scheme**, where the operating system keeps a table indicating which parts of memory are available and which are occupied.

The **dynamic storage-allocation problem** concerns how to satisfy a request of size n from a list of free holes. There are many solutions to this problem. The first-fit, best-fit, and worst-fit strategies are the most common ones used to select a free hole from the set of available holes.
-   **First fit:** Allocate the first hole that is big enough.
-   **Best fit:** Allocate the smallest hole that is big enough.
-   **Worst fit:** Allocate the largest hole.

**Fragmentation:** Both the first-fit and best-fit strategies for memory allocation suffer from **external fragmentation**. As processes are loaded and removed from memory, the free memory space is broken into little pieces. External fragmentation exists when there is enough total memory space to satisfy a request but the available spaces are not contiguous.

## Paging

**Paging** is a memory-management scheme that permits the physical address space of a process to be noncontiguous. Paging avoids external fragmentation and the need for compaction.

The basic method for implementing paging involves breaking physical memory into fixed-sized blocks called **frames** and breaking logical memory into blocks of the same size called **pages**. When a process is to be executed, its pages are loaded into any available memory frames from the backing store.

Every address generated by the CPU is divided into two parts: a **page number (p)** and a **page offset (d)**. The page number is used as an index into a **page table**. The page table contains the base address of each page in physical memory. This base address is combined with the page offset to define the physical memory address that is sent to the memory unit.

## Structure of the Page Table

For a system with a large logical address space, the page table itself can be excessively large.

-   **Hierarchical Paging:** A common approach is to use a two-level paging scheme, in which the page table itself is also paged.
-   **Hashed Page Tables:** A common approach for handling address spaces larger than 32 bits is to use a hashed page table, with the hash value being the virtual page number.
-   **Inverted Page Tables:** An inverted page table has one entry for each real page (or frame) of memory. Each entry consists of the virtual address of the page stored in that real memory location, with information about the process that owns that page.

## Segmentation

**Segmentation** is a memory-management scheme that supports the user view of memory. A logical address space is a collection of segments. Each segment has a name and a length. The addresses specify both the segment name and the offset within the segment.

A logical address consists of a two-tuple: <segment-number, offset>. The segment number is used as an index into a **segment table**. The segment table entry contains the base address of the segment in physical memory and the limit of the segment.

## Example: The Intel Pentium

The Intel Pentium architecture supports both segmentation and paging. The CPU generates logical addresses, which are given to the segmentation unit. The segmentation unit produces a linear address for each logical address. The linear address is then given to the paging unit, which in turn generates the physical address in main memory.
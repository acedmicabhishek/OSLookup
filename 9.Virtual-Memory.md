# Chapter 9: Virtual Memory

## Background

Virtual memory is a technique that allows the execution of processes that are not completely in memory. The main advantage of this scheme is that programs can be larger than physical memory.

Virtual memory abstracts main memory into an extremely large, uniform array of storage, separating the logical memory as viewed by the user from physical memory. This technique frees programmers from the concerns of memory-storage limitations.

## Demand Paging

Demand paging is a common method for implementing virtual memory. With demand-paged virtual memory, pages are loaded only when they are demanded during program execution. Pages that are never accessed are thus never loaded into physical memory.

A **pager** is a component of the virtual memory system that brings pages into memory. When a process tries to access a page that was not brought into memory, a **page fault** occurs. The operating system's page-fault trap handler finds the desired page on the backing store, loads it into a free frame in main memory, and updates the page table.

## Copy-on-Write

Copy-on-write (COW) is a resource-management technique. If a resource is duplicated but not modified, it is not necessary to create a new resource; the resource can be shared. If the resource is modified, a new resource is created.

COW is often used in virtual memory systems. When a process creates a copy of itself (e.g., with `fork()`), the pages of the parent process can be shared with the child process. If either process modifies a page, a copy of the shared page is created.

## Page Replacement

If there are no free frames, and a page fault occurs, the operating system must find a frame that is not currently in use and free it. A frame is freed by writing its contents to swap space and changing the page table to indicate that the page is no longer in memory.

There are many different page-replacement algorithms. The goal is to select a page that will not be used for the longest period of time.

-   **FIFO (First-In, First-Out):** The simplest page-replacement algorithm. The page that has been in memory the longest is replaced.
-   **Optimal Page Replacement:** Replaces the page that will not be used for the longest period of time. This is the best algorithm, but it is impossible to implement because it requires future knowledge.
-   **LRU (Least Recently Used):** Replaces the page that has not been used for the longest period of time.
-   **Approximations to LRU:**
    -   **Additional-Reference-Bits Algorithm:** A reference bit is associated with each entry in the page table. The bit is set to 1 when the page is referenced.
    -   **Second-Chance Algorithm:** A FIFO replacement algorithm that checks the reference bit.
-   **Counting-Based Page Replacement:**
    -   **LFU (Least Frequently Used):** Replaces the page with the smallest count of references.
    -   **MFU (Most Frequently Used):** Replaces the page with the largest count of references.

## Allocation of Frames

The operating system must decide how many frames to allocate to each process.

-   **Fixed Allocation:** Gives a process a fixed number of frames.
-   **Priority Allocation:** Uses a proportional allocation scheme where the ratio of frames allocated to each process varies with the process's priority.

**Global vs. Local Allocation:**
-   **Global replacement:** A process can select a replacement frame from the set of all frames, even if that frame is currently allocated to some other process.
-   **Local replacement:** A process can only select from its own set of allocated frames.

## Thrashing

If a process does not have enough frames, the page-fault rate is very high. This leads to low CPU utilization. The operating system, seeing the low CPU utilization, may increase the degree of multiprogramming. This results in a state called **thrashing**, where the system is spending more time paging than executing.

To prevent thrashing, we can use a **working-set model**. The working set of a process is the set of pages that it is currently using. The operating system monitors the working set of each process and allocates to it enough frames to hold its working set.

## Memory-Mapped Files

Memory-mapped files allow a part of a file on disk to be mapped to a process's address space. This allows the process to access the file as if it were an array in memory.

## Allocating Kernel Memory

Kernel memory is often allocated from a different memory pool from the one used to satisfy user-mode requests. The kernel requests memory for data structures of varying sizes. Two common strategies for managing kernel memory are the **buddy system** and **slab allocation**.

## Other Considerations

-   **Prepaging:** To reduce the large number of page faults that occurs at process startup, we can prepage, or bring into memory at one time, all the pages that will be needed.
-   **Page Size:** The size of a page is a hardware decision, but the choice has to be made carefully.
-   **TLB Reach:** The TLB reach is the amount of memory accessible from the TLB. It is the number of entries in the TLB multiplied by the page size.

## Operating System Examples

-   **Windows:** Uses demand paging with clustering. Clustering brings in pages surrounding the faulting page.
-   **Linux:** Uses demand paging.

# Chapter 6: Process Synchronization

## Background

Concurrent access to shared data may result in data inconsistency. Maintaining data consistency requires mechanisms to ensure the orderly execution of cooperating processes.

Consider a system consisting of multiple processes, all accessing and manipulating the same data. If this is not handled correctly, the final state of the shared data will depend on the order in which the processes are scheduled, leading to a **race condition**. To guard against race conditions, we need to ensure that only one process at a time can manipulate the shared data.

## The Critical-Section Problem

A **critical section** is a segment of code in which a process accesses shared resources. The critical-section problem is to design a protocol that the processes can use to cooperate. Each process must request permission to enter its critical section. The section of code implementing this request is the **entry section**. The critical section may be followed by an **exit section**. The remaining code is the **remainder section**.

A solution to the critical-section problem must satisfy the following three requirements:
1.  **Mutual Exclusion:** If process Pi is executing in its critical section, then no other processes can be executing in their critical sections.
2.  **Progress:** If no process is executing in its critical section and some processes wish to enter their critical sections, then the selection of the processes that will enter the critical section next cannot be postponed indefinitely.
3.  **Bounded Waiting:** A bound must exist on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted.

## Peterson's Solution

Peterson's solution is a classic software-based solution to the critical-section problem. It is restricted to two processes that alternate execution between their critical sections and remainder sections. The two processes share two variables: `int turn;` and `boolean flag[2];`.

## Synchronization Hardware

Software-based solutions like Peterson's are not guaranteed to work on modern computer architectures. Many systems provide hardware support for critical section code. The hardware instructions are **atomic**, meaning they are executed as one uninterruptible unit.

Common hardware instructions for synchronization include:
-   **Test and Set:** Tests a memory word and sets it to a new value in a single atomic operation.
-   **Compare and Swap:** Compares the contents of a memory location to a given value and, only if they are the same, modifies the contents of that memory location to a given new value.

## Mutex Locks

A **mutex lock** (or simply mutex) is a synchronization tool used to solve the critical-section problem. A process must acquire the lock before entering a critical section; it releases the lock when it exits the critical section. The `acquire()` function acquires the lock, and the `release()` function releases the lock. A mutex lock is a boolean variable indicating if the lock is available or not.

## Semaphores

A **semaphore** is a more sophisticated synchronization tool than a mutex lock. A semaphore S is an integer variable that, apart from initialization, is accessed only through two standard atomic operations: `wait()` and `signal()`.

-   `wait(S)`: Decrements the semaphore. If the value becomes negative, the process is blocked.
-   `signal(S)`: Increments the semaphore. If the value is not positive, a blocked process is unblocked.

There are two types of semaphores:
-   **Counting semaphore:** The value can range over an unrestricted domain.
-   **Binary semaphore:** The value can range only between 0 and 1. This is functionally similar to a mutex lock.

## Classic Problems of Synchronization

-   **The Bounded-Buffer Problem:** Also known as the producer-consumer problem. It involves a buffer of a fixed size that is shared between a producer process and a consumer process.
-   **The Readers-Writers Problem:** A database is to be shared among several concurrent processes. Some of these processes may want only to read the database (readers), whereas others may want to update (that is, to read and write) the database (writers).
-   **The Dining-Philosophers Problem:** A classic synchronization problem that is used to evaluate situations where a set of processes requires several resources, and the resources are not all available at the same time.

## Monitors

A **monitor** is a high-level abstraction that provides a convenient and effective mechanism for process synchronization. A monitor is an abstract data type that includes a set of programmer-defined operations that are provided with mutual exclusion.

A monitor type has a set of variables and a set of procedures. A process can call the procedures of the monitor but cannot access the internal variables directly. Only one process may be active within the monitor at a time.

## Synchronization Examples

-   **POSIX Synchronization:** Pthreads provides mutex locks, condition variables, and semaphores.
-   **Java Synchronization:** Java provides a `synchronized` keyword to create synchronized methods and blocks. It also provides a rich API for synchronization in the `java.util.concurrent` package.

## Alternative Approaches

-   **Transactional Memory:** A memory transaction is a sequence of memory read-write operations that are atomic. If a transaction completes, all its memory modifications are committed. If it aborts, all its modifications are discarded.
-   **OpenMP:** A set of compiler directives and an API for C, C++, and Fortran that provides support for parallel programming in shared-memory environments.
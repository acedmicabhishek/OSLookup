# Chapter 5: CPU Scheduling

## Basic Concepts

In a single-processor system, only one process can run at a time. Others must wait until the CPU is free and can be rescheduled. The objective of multiprogramming is to have some process running at all times, to maximize CPU utilization.

The idea is simple: a process is executed until it must wait, typically for the completion of some I/O request. In a simple computer system, the CPU then sits idle. All this waiting time is wasted; no useful work is accomplished. With multiprogramming, we try to use this time productively. Several processes are kept in memory at one time. When one process has to wait, the operating system takes the CPU away from that process and gives the CPU to another process.

### CPU–I/O Burst Cycle

Process execution consists of a cycle of CPU execution and I/O wait. Processes alternate between these two states. Process execution begins with a CPU burst. That is followed by an I/O burst, which is followed by another CPU burst, then another I/O burst, and so on. Eventually, the final CPU burst ends with a system request to terminate execution.

### CPU Scheduler

Whenever the CPU becomes idle, the operating system must select one of the processes in the ready queue to be executed. The selection process is carried out by the short-term scheduler (or CPU scheduler). The scheduler selects a process from the processes in memory that are ready to execute and allocates the CPU to that process.

### Preemptive Scheduling

CPU-scheduling decisions may take place under the following four circumstances:
1.  When a process switches from the running state to the waiting state.
2.  When a process switches from the running state to the ready state.
3.  When a process switches from the waiting state to the ready state.
4.  When a process terminates.

When scheduling takes place only under circumstances 1 and 4, we say that the scheduling scheme is nonpreemptive or cooperative. Otherwise, it is preemptive.

## Scheduling Criteria

Different CPU-scheduling algorithms have different properties, and the choice of a particular algorithm may favor one class of processes over another. Many criteria have been suggested for comparing CPU-scheduling algorithms. The criteria include the following:

-   **CPU utilization:** We want to keep the CPU as busy as possible.
-   **Throughput:** The number of processes that are completed per time unit.
-   **Turnaround time:** The interval from the time of submission of a process to the time of completion.
-   **Waiting time:** The sum of the periods spent waiting in the ready queue.
-   **Response time:** The time from the submission of a request until the first response is produced.

## Scheduling Algorithms

CPU scheduling deals with the problem of deciding which of the processes in the ready queue is to be allocated the CPU.

-   **First-Come, First-Served (FCFS) Scheduling:** The process that requests the CPU first is allocated the CPU first.
-   **Shortest-Job-First (SJF) Scheduling:** This algorithm associates with each process the length of the process’s next CPU burst. When the CPU is available, it is assigned to the process that has the smallest next CPU burst.
-   **Priority Scheduling:** A priority is associated with each process, and the CPU is allocated to the process with the highest priority.
-   **Round-Robin (RR) Scheduling:** The round-robin (RR) scheduling algorithm is designed especially for timesharing systems. It is similar to FCFS scheduling, but preemption is added to enable the system to switch between processes.
-   **Multilevel Queue Scheduling:** This algorithm partitions the ready queue into several separate queues. The processes are permanently assigned to one queue, generally based on some property of the process, such as memory size, process priority, or process type.
-   **Multilevel Feedback Queue Scheduling:** This algorithm allows a process to move between queues. The idea is to separate processes with different CPU-burst characteristics.

## Thread Scheduling

On operating systems that support kernel-level threads, it is kernel-level threads—not processes—that are being scheduled by the operating system. User-level threads are managed by a thread library, and the kernel is unaware of them.

## Multiple-Processor Scheduling

If multiple CPUs are available, load sharing becomes possible. However, scheduling issues become correspondingly more complex. Many possibilities have been tried, and as with single-processor scheduling, there is no one best solution.

-   **Asymmetric Multiprocessing:** All scheduling decisions, I/O processing, and other system activities are handled by a single processor—the master server.
-   **Symmetric Multiprocessing (SMP):** Each processor is self-scheduling. All processes may be in a common ready queue, or each processor may have its own private queue of ready processes.

## Real-Time CPU Scheduling

Real-time systems are those in which the time at which a task completes is a critical part of its correctness.

-   **Soft Real-Time Systems:** Provide no guarantee as to when a critical real-time process will be scheduled.
-   **Hard Real-Time Systems:** Have stricter requirements. A task must be serviced by its deadline.

## Operating System Examples

-   **Linux Scheduling:** The Linux scheduler is a preemptive, priority-based algorithm with two separate priority ranges: a real-time range from 0 to 99 and a nice value ranging from 100 to 139.
-   **Windows Scheduling:** Windows uses a priority-based, preemptive scheduling algorithm. The Windows scheduler ensures that the highest-priority thread will always run.

## Algorithm Evaluation

How do we select a CPU-scheduling algorithm for a particular system? There are many scheduling algorithms, each with its own parameters. As a result, selecting an algorithm can be difficult.

-   **Deterministic Modeling:** This method takes a particular predetermined workload and defines the performance of each algorithm for that workload.
-   **Queueing Models:** The computer system is described as a network of servers. Each server has a queue of waiting processes.
-   **Simulations:** Simulations involve programming a model of the computer system.